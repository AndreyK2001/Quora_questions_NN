{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense, Dropout, Merge, BatchNormalization\n",
    "from keras.layers import TimeDistributed, Lambda, LSTM, Convolution1D, GlobalMaxPooling1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train_Quora.csv\")\n",
    "train.fillna(\"\", inplace=True)\n",
    "question1, question2 = train[\"question1\"], train[\"question1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "questions = question1 + question2\n",
    "token = Tokenizer(num_words=200000)\n",
    "token.fit_on_texts(questions)\n",
    "question1_word_sequences = token.texts_to_sequences(question1)\n",
    "question2_word_sequences = token.texts_to_sequences(question2)\n",
    "word_index = token.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_param = min(200000, len(word_index))\n",
    "q1_data = pad_sequences(question1_word_sequences, maxlen=20)\n",
    "q2_data = pad_sequences(question2_word_sequences, maxlen=20)\n",
    "labels = np.array(train[\"is_duplicate\"], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.stack((q1_data, q2_data), axis=1)\n",
    "y = labels\n",
    "Q1_train = X[:,0]\n",
    "Q2_train = X[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_td1 = Sequential()\n",
    "model_td1.add(Embedding(words_param + 1, 250, input_length=20, trainable=False))\n",
    "model_td1.add(TimeDistributed(Dense(250, activation=\"relu\")))\n",
    "model_td1.add(Lambda(lambda x: K.max(x, axis=1), output_shape=(250, )))\n",
    "\n",
    "\n",
    "model_td2 = Sequential()\n",
    "model_td2.add(Embedding(words_param + 1, 250,input_length=20, trainable=False))\n",
    "model_td2.add(TimeDistributed(Dense(250, activation=\"relu\")))\n",
    "model_td2.add(Lambda(lambda x: K.max(x, axis=1), output_shape=(250, )))\n",
    "\n",
    "\n",
    "#данные \"псевдомодели\" отвечают за ввод данных в основную модель\n",
    "#отвечают в основном за переформатирование входного массива\n",
    "\n",
    "model_1 = Sequential()\n",
    "model_1.add(Merge([model_td1, model_td2], mode=\"concat\"))\n",
    "#Merge соединяет два потока данных из вводных моделей\n",
    "model_1.add(BatchNormalization())\n",
    "for i in range(6):\n",
    "    model_1.add(Dropout(0.9))\n",
    "    model_1.add(Dense(2000, activation=\"relu\"))\n",
    "    model_1.add(BatchNormalization())\n",
    "\n",
    "model_1.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit([Q1_train, Q2_train], y, batch_size=100, epochs=25, validation_split=0.1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Вместо предыдущих 3 ячеек можно выполнить 3 ниже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"Qoura_model.json\", \"r\") as json_file:\n",
    "    loaded_model = json_file.read()\n",
    "#загружаем модель\n",
    "model = model_from_json(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#загружаем веса в модель\n",
    "model.load_weights(\"Quora_model_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Загружаем данные для теста и предсказываем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test_Quora.csv\")\n",
    "test.fillna(\"\", inplace=True)\n",
    "test_id=test[\"test_id\"]\n",
    "question1, question2 = test[\"question1\"], test[\"question1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "question1_word_sequences = token.texts_to_sequences(question1)\n",
    "question2_word_sequences = token.texts_to_sequences(question2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q1_data = pad_sequences(question1_word_sequences, maxlen=20)\n",
    "q2_data = pad_sequences(question2_word_sequences, maxlen=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.stack((q1_data, q2_data), axis=1)\n",
    "Q1_test = X[:,0]\n",
    "Q2_test = X[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"sample_submission_Quora.csv\")\n",
    "submission[\"is_duplicate\"] = pd.DataFrame(model.predict([Q1_test, Q2_test], batch_size=100, verbose=1)[:, 0])\n",
    "submission.to_csv(\"mysub.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
